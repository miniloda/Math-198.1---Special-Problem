{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-13T19:09:08.192764Z",
     "start_time": "2025-04-13T19:09:08.059324Z"
    }
   },
   "source": "import utils",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:09:08.205596Z",
     "start_time": "2025-04-13T19:09:08.201788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "municipal_list = []\n",
    "with open('municipals.txt') as f:\n",
    "    for line in f:\n",
    "        municipal_list.append(line.strip())\n",
    "print(municipal_list)"
   ],
   "id": "c63d0b8f5ac5a658",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ajuy', 'Alimodian', 'Anilao', 'Badiangan', 'Balasan', 'Banate', 'Barotac Nuevo', 'Barotac Viejo', 'Batad', 'Bingawan', 'Cabatuan', 'Calinog', 'Carles', 'Passi City', 'Concepcion', 'Dingle', 'Duenas', 'Dumangas', 'Estancia', 'Guimbal', 'Iloilo City', 'Igbaras', 'Janiuay', 'Lambunao', 'Leganes', 'Lemery', 'Leon', 'Maasin', 'Miagao', 'Mina', 'New Lucena', 'Oton', 'Pavia', 'Pototan', 'San Dionisio', 'San Enrique', 'San Joaquin', 'San Miguel', 'San Rafael', 'Santa Barbara', 'Sara', 'Tigbauan', 'Tubungan', 'Zarraga']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:09:08.481451Z",
     "start_time": "2025-04-13T19:09:08.302791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make a csv file for municipals and their corresponding coordinates\n",
    "file_name = 'municipal_coordinates.csv'\n",
    "column_names = ['Municipality', 'Latitude', 'Longitude']\n",
    "municipal_coords = utils.municipal_coordinates(file_name, municipal_list, column_names, rewrite_file=False)"
   ],
   "id": "82afc9135337f2fa",
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Content already exists in the file. Set rewrite_file to True to overwrite it.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m file_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmunicipal_coordinates.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      3\u001B[0m column_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMunicipality\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLatitude\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLongitude\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 4\u001B[0m municipal_coords \u001B[38;5;241m=\u001B[39m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmunicipal_coordinates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmunicipal_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrewrite_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/Math-198.1---Special-Problem/utils.py:60\u001B[0m, in \u001B[0;36mmunicipal_coordinates\u001B[0;34m(file_name, municipals, column_names, rewrite_file)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file_name, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m     59\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m file\u001B[38;5;241m.\u001B[39mread()\u001B[38;5;241m.\u001B[39mstrip():  \u001B[38;5;66;03m# Check if the file has non-empty content\u001B[39;00m\n\u001B[0;32m---> 60\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[1;32m     61\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent already exists in the file. Set rewrite_file to True to overwrite it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     62\u001B[0m             )\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# No file exists, so no action needed\u001B[39;00m\n",
      "\u001B[0;31mException\u001B[0m: Content already exists in the file. Set rewrite_file to True to overwrite it."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:09:21.556367Z",
     "start_time": "2025-04-13T19:09:21.532772Z"
    }
   },
   "cell_type": "code",
   "source": "municipal_coords",
   "id": "9605c07121b322f6",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'municipal_coords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmunicipal_coords\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'municipal_coords' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:09:21.872141Z",
     "start_time": "2025-04-13T19:09:21.848552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the weather data for each municipality (running list, as we have limited calls per day)\n",
    "weather_data = utils.weather_to_jsonl(municipal_coords, 'municipal_weather_data.jsonl', rewrite_file=False)"
   ],
   "id": "7cb634644785a0d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'municipal_coords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# get the weather data for each municipality (running list, as we have limited calls per day)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m weather_data \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mweather_to_jsonl(\u001B[43mmunicipal_coords\u001B[49m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmunicipal_weather_data.jsonl\u001B[39m\u001B[38;5;124m'\u001B[39m, rewrite_file\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'municipal_coords' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:09:22.047950Z",
     "start_time": "2025-04-13T19:09:22.038197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get population data for each municipality\n",
    "import pandas as pd\n",
    "population_df = pd.read_csv(\"population_data.csv\")\n",
    "population_df\n",
    "len(population_df)"
   ],
   "id": "413743ac7139d1d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:09:22.227796Z",
     "start_time": "2025-04-13T19:09:22.184405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use 2010 and 2015 population for each to estimate 2011-2014 linearly, the same with 2015 and 2020. 2015 and 2020 will also be used to estimate 2021-2024.\n",
    "pop_2011 = []\n",
    "pop_2012 = []\n",
    "pop_2013 = []\n",
    "pop_2014 = []\n",
    "pop_2016 = []\n",
    "pop_2017 = []\n",
    "pop_2018 = []\n",
    "pop_2019 = []\n",
    "pop_2021 = []\n",
    "pop_2022 = []\n",
    "pop_2023 = []\n",
    "pop_2024 = []\n",
    "\n",
    "for municipal in municipal_list:\n",
    "    # Get the population for the municipal\n",
    "    municipal_population = population_df[population_df['Municipal'] == municipal]\n",
    "    # Get the population for 2010, 2015, and 2020\n",
    "    population_2010 = municipal_population['2010'].values[0]\n",
    "    population_2015 = municipal_population['2015'].values[0]\n",
    "    population_2020 = municipal_population['2020'].values[0]\n",
    "    \n",
    "    # Calculate slopes\n",
    "    slope_2010 = (population_2015 - population_2010) / 5\n",
    "    slope_2015 = (population_2020 - population_2015) / 5\n",
    "    \n",
    "    # Calculate the population for 2011-2014\n",
    "    pop_2011.append(population_2010 + slope_2010)\n",
    "    pop_2012.append(population_2010 + slope_2010 * 2)\n",
    "    pop_2013.append(population_2010 + slope_2010 * 3)\n",
    "    pop_2014.append(population_2010 + slope_2010 * 4)\n",
    "    \n",
    "    # Calculate the population for 2016-2019\n",
    "    pop_2016.append(population_2015 + slope_2015)\n",
    "    pop_2017.append(population_2015 + slope_2015 * 2)\n",
    "    pop_2018.append(population_2015 + slope_2015 * 3)\n",
    "    pop_2019.append(population_2015 + slope_2015 * 4)\n",
    "    \n",
    "    # Calculate the population for 2021-2024\n",
    "    pop_2021.append(population_2020 + slope_2015)\n",
    "    pop_2022.append(population_2020 + slope_2015 * 2)\n",
    "    pop_2023.append(population_2020 + slope_2015 * 3)\n",
    "    pop_2024.append(population_2020 + slope_2015 * 4)\n",
    "\n",
    "# Add the columns to the dataframe\n",
    "population_df['2011'] = pop_2011\n",
    "population_df['2012'] = pop_2012\n",
    "population_df['2013'] = pop_2013\n",
    "population_df['2014'] = pop_2014\n",
    "population_df['2016'] = pop_2016\n",
    "population_df['2017'] = pop_2017\n",
    "population_df['2018'] = pop_2018\n",
    "population_df['2019'] = pop_2019\n",
    "population_df['2021'] = pop_2021\n",
    "population_df['2022'] = pop_2022\n",
    "population_df['2023'] = pop_2023\n",
    "population_df['2024'] = pop_2024\n",
    "\n",
    "# Order the columns\n",
    "population_df = population_df[['Municipal', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024']]\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "population_df.to_csv('population_data_complete.csv', index=False)"
   ],
   "id": "71e14c636a8b9104",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T19:11:40.385899Z",
     "start_time": "2025-04-13T19:11:14.969788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import data_cleaning_utils\n",
    "\n",
    "# for loop the municipalities and save the data\n",
    "with open('municipals.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        municipal = line.strip()\n",
    "        \n",
    "        data_cleaning_utils.get_merged_df(municipal)"
   ],
   "id": "2200896333043944",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data for Ajuy\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Ajuy has been cleaned and saved to data/Merged Data/Ajuy_merged.csv\n",
      "Cleaning data for Alimodian\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      1 2014-01-19\n",
      "2  2014     3      1 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Alimodian has been cleaned and saved to data/Merged Data/Alimodian_merged.csv\n",
      "Cleaning data for Anilao\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Anilao has been cleaned and saved to data/Merged Data/Anilao_merged.csv\n",
      "Cleaning data for Badiangan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Badiangan has been cleaned and saved to data/Merged Data/Badiangan_merged.csv\n",
      "Cleaning data for Balasan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Balasan has been cleaned and saved to data/Merged Data/Balasan_merged.csv\n",
      "Cleaning data for Banate\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      1 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Banate has been cleaned and saved to data/Merged Data/Banate_merged.csv\n",
      "Cleaning data for Barotac Nuevo\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Barotac Nuevo has been cleaned and saved to data/Merged Data/Barotac Nuevo_merged.csv\n",
      "Cleaning data for Barotac Viejo\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      1 2014-02-09\n",
      "Data for Barotac Viejo has been cleaned and saved to data/Merged Data/Barotac Viejo_merged.csv\n",
      "Cleaning data for Batad\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      1 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Batad has been cleaned and saved to data/Merged Data/Batad_merged.csv\n",
      "Cleaning data for Bingawan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      2 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Bingawan has been cleaned and saved to data/Merged Data/Bingawan_merged.csv\n",
      "Cleaning data for Cabatuan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-12\n",
      "1  2014     2      3 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Cabatuan has been cleaned and saved to data/Merged Data/Cabatuan_merged.csv\n",
      "Cleaning data for Calinog\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      1 2014-01-19\n",
      "2  2014     3      1 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      2 2014-02-09\n",
      "Data for Calinog has been cleaned and saved to data/Merged Data/Calinog_merged.csv\n",
      "Cleaning data for Carles\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Carles has been cleaned and saved to data/Merged Data/Carles_merged.csv\n",
      "Cleaning data for Passi City\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      2 2014-01-12\n",
      "1  2014     2      1 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Passi City has been cleaned and saved to data/Merged Data/Passi City_merged.csv\n",
      "Cleaning data for Concepcion\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Concepcion has been cleaned and saved to data/Merged Data/Concepcion_merged.csv\n",
      "Cleaning data for Dingle\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Dingle has been cleaned and saved to data/Merged Data/Dingle_merged.csv\n",
      "Cleaning data for Duenas\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      1 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Duenas has been cleaned and saved to data/Merged Data/Duenas_merged.csv\n",
      "Cleaning data for Dumangas\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      1 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Dumangas has been cleaned and saved to data/Merged Data/Dumangas_merged.csv\n",
      "Cleaning data for Estancia\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Estancia has been cleaned and saved to data/Merged Data/Estancia_merged.csv\n",
      "Cleaning data for Guimbal\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      2 2014-01-12\n",
      "1  2014     2      1 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Guimbal has been cleaned and saved to data/Merged Data/Guimbal_merged.csv\n",
      "Cleaning data for Iloilo City\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1     12 2014-01-12\n",
      "1  2014     2     13 2014-01-19\n",
      "2  2014     3      7 2014-01-26\n",
      "3  2014     4     12 2014-02-02\n",
      "4  2014     5      5 2014-02-09\n",
      "Data for Iloilo City has been cleaned and saved to data/Merged Data/Iloilo City_merged.csv\n",
      "Cleaning data for Igbaras\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Igbaras has been cleaned and saved to data/Merged Data/Igbaras_merged.csv\n",
      "Cleaning data for Janiuay\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      2 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      1 2014-02-09\n",
      "Data for Janiuay has been cleaned and saved to data/Merged Data/Janiuay_merged.csv\n",
      "Cleaning data for Lambunao\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      1 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Lambunao has been cleaned and saved to data/Merged Data/Lambunao_merged.csv\n",
      "Cleaning data for Leganes\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Leganes has been cleaned and saved to data/Merged Data/Leganes_merged.csv\n",
      "Cleaning data for Lemery\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Lemery has been cleaned and saved to data/Merged Data/Lemery_merged.csv\n",
      "Cleaning data for Leon\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      1 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Leon has been cleaned and saved to data/Merged Data/Leon_merged.csv\n",
      "Cleaning data for Maasin\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Maasin has been cleaned and saved to data/Merged Data/Maasin_merged.csv\n",
      "Cleaning data for Miagao\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      1 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Miagao has been cleaned and saved to data/Merged Data/Miagao_merged.csv\n",
      "Cleaning data for Mina\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Mina has been cleaned and saved to data/Merged Data/Mina_merged.csv\n",
      "Cleaning data for New Lucena\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      2 2014-01-19\n",
      "2  2014     3      1 2014-01-26\n",
      "3  2014     4      2 2014-02-02\n",
      "4  2014     5      1 2014-02-09\n",
      "Data for New Lucena has been cleaned and saved to data/Merged Data/New Lucena_merged.csv\n",
      "Cleaning data for Oton\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      2 2014-01-12\n",
      "1  2014     2      4 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Oton has been cleaned and saved to data/Merged Data/Oton_merged.csv\n",
      "Cleaning data for Pavia\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      2 2014-01-12\n",
      "1  2014     2      3 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      1 2014-02-02\n",
      "4  2014     5      1 2014-02-09\n",
      "Data for Pavia has been cleaned and saved to data/Merged Data/Pavia_merged.csv\n",
      "Cleaning data for Pototan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      1 2014-01-26\n",
      "3  2014     4      2 2014-02-02\n",
      "4  2014     5      3 2014-02-09\n",
      "Data for Pototan has been cleaned and saved to data/Merged Data/Pototan_merged.csv\n",
      "Cleaning data for San Dionisio\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for San Dionisio has been cleaned and saved to data/Merged Data/San Dionisio_merged.csv\n",
      "Cleaning data for San Enrique\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      1 2014-02-09\n",
      "Data for San Enrique has been cleaned and saved to data/Merged Data/San Enrique_merged.csv\n",
      "Cleaning data for San Joaquin\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for San Joaquin has been cleaned and saved to data/Merged Data/San Joaquin_merged.csv\n",
      "Cleaning data for San Miguel\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-12\n",
      "1  2014     2      1 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for San Miguel has been cleaned and saved to data/Merged Data/San Miguel_merged.csv\n",
      "Cleaning data for San Rafael\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for San Rafael has been cleaned and saved to data/Merged Data/San Rafael_merged.csv\n",
      "Cleaning data for Santa Barbara\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-12\n",
      "1  2014     2      2 2014-01-19\n",
      "2  2014     3      1 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Santa Barbara has been cleaned and saved to data/Merged Data/Santa Barbara_merged.csv\n",
      "Cleaning data for Sara\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      2 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      1 2014-02-02\n",
      "4  2014     5      1 2014-02-09\n",
      "Data for Sara has been cleaned and saved to data/Merged Data/Sara_merged.csv\n",
      "Cleaning data for Tigbauan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      1 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Tigbauan has been cleaned and saved to data/Merged Data/Tigbauan_merged.csv\n",
      "Cleaning data for Tubungan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      0 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Tubungan has been cleaned and saved to data/Merged Data/Tubungan_merged.csv\n",
      "Cleaning data for Zarraga\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-12\n",
      "1  2014     2      1 2014-01-19\n",
      "2  2014     3      0 2014-01-26\n",
      "3  2014     4      0 2014-02-02\n",
      "4  2014     5      0 2014-02-09\n",
      "Data for Zarraga has been cleaned and saved to data/Merged Data/Zarraga_merged.csv\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f1244d9f142b8b09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

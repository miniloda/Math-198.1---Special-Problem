{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-06T15:20:52.808136Z",
     "start_time": "2025-04-06T15:20:52.731951Z"
    }
   },
   "source": "import utils",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T15:20:52.820060Z",
     "start_time": "2025-04-06T15:20:52.816860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "municipal_list = []\n",
    "with open('municipals.txt') as f:\n",
    "    for line in f:\n",
    "        municipal_list.append(line.strip())\n",
    "print(municipal_list)"
   ],
   "id": "c63d0b8f5ac5a658",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ajuy', 'Alimodian', 'Anilao', 'Badiangan', 'Balasan', 'Banate', 'Barotac Nuevo', 'Barotac Viejo', 'Batad', 'Bingawan', 'Cabatuan', 'Calinog', 'Carles', 'Passi City', 'Concepcion', 'Dingle', 'Duenas', 'Dumangas', 'Estancia', 'Guimbal', 'Iloilo City', 'Igbaras', 'Janiuay', 'Lambunao', 'Leganes', 'Lemery', 'Leon', 'Maasin', 'Miagao', 'Mina', 'New Lucena', 'Oton', 'Pavia', 'Pototan', 'San Dionisio', 'San Enrique', 'San Joaquin', 'San Rafael', 'Santa Barbara', 'Sara', 'Tigbauan', 'Tubungan', 'Zarraga']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T15:20:52.901678Z",
     "start_time": "2025-04-06T15:20:52.867963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make a csv file for municipals and their corresponding coordinates\n",
    "file_name = 'municipal_coordinates.csv'\n",
    "column_names = ['Municipality', 'Latitude', 'Longitude']\n",
    "municipal_coords = utils.municipal_coordinates(file_name, municipal_list, column_names, rewrite_file=False)"
   ],
   "id": "82afc9135337f2fa",
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Content already exists in the file. Set rewrite_file to True to overwrite it.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m file_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmunicipal_coordinates.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      3\u001B[0m column_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMunicipality\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLatitude\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLongitude\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 4\u001B[0m municipal_coords \u001B[38;5;241m=\u001B[39m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmunicipal_coordinates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmunicipal_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrewrite_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/Math-198.1---Special-Problem/utils.py:60\u001B[0m, in \u001B[0;36mmunicipal_coordinates\u001B[0;34m(file_name, municipals, column_names, rewrite_file)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file_name, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m     59\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m file\u001B[38;5;241m.\u001B[39mread()\u001B[38;5;241m.\u001B[39mstrip():  \u001B[38;5;66;03m# Check if the file has non-empty content\u001B[39;00m\n\u001B[0;32m---> 60\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[1;32m     61\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent already exists in the file. Set rewrite_file to True to overwrite it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     62\u001B[0m             )\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# No file exists, so no action needed\u001B[39;00m\n",
      "\u001B[0;31mException\u001B[0m: Content already exists in the file. Set rewrite_file to True to overwrite it."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T15:20:52.917376472Z",
     "start_time": "2025-04-06T15:09:02.938594Z"
    }
   },
   "cell_type": "code",
   "source": "municipal_coords",
   "id": "9605c07121b322f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ajuy': (11.1246161, 123.0113568),\n",
       " 'Alimodian': (10.8773088, 122.367428),\n",
       " 'Anilao': (11.0002604, 122.740723),\n",
       " 'Badiangan': (10.9964817, 122.5259596),\n",
       " 'Balasan': (11.4592707, 123.0901539),\n",
       " 'Banate': (11.000592, 122.8155554),\n",
       " 'Barotac Nuevo': (10.9216153, 122.740723),\n",
       " 'Barotac Viejo': (11.0625316, 122.8761309),\n",
       " 'Batad': (11.4169972, 123.1126559),\n",
       " 'Bingawan': (11.2052871, 122.593828),\n",
       " 'Cabatuan': (10.9091869, 122.5146439),\n",
       " 'Calinog': (11.1457896, 122.5146439),\n",
       " 'Carles': (11.5687532, 123.2363246),\n",
       " 'Passi City': (11.1687967, 122.650351),\n",
       " 'Concepcion': (11.2147313, 123.1044322),\n",
       " 'Dingle': (11.0111309, 122.650351),\n",
       " 'Duenas': (11.0671826, 122.593828),\n",
       " 'Dumangas': (10.8484102, 122.695547),\n",
       " 'Estancia': (11.4619823, 123.1463992),\n",
       " 'Guimbal': (10.6686639, 122.2994127),\n",
       " 'Iloilo City': (10.7201501, 122.5621063),\n",
       " 'Igbaras': (10.7162878, 122.2649758),\n",
       " 'Janiuay': (10.9987667, 122.424074),\n",
       " 'Lambunao': (11.077708, 122.424074),\n",
       " 'Leganes': (10.7916725, 122.593828),\n",
       " 'Lemery': (11.214412, 122.9212265),\n",
       " 'Leon': (10.8208599, 122.3447611),\n",
       " 'Maasin': (10.8914767, 122.4333105),\n",
       " 'Miagao': (10.6705468, 122.1973081),\n",
       " 'Mina': (10.9516879, 122.5712101),\n",
       " 'New Lucena': (10.8729712, 122.5712101),\n",
       " 'Oton': (10.7240176, 122.4562615),\n",
       " 'Pavia': (10.7603368, 122.5259596),\n",
       " 'Pototan': (10.9239245, 122.6390489),\n",
       " 'San Dionisio': (11.3101048, 123.1014056),\n",
       " 'San Enrique': (11.1098942, 122.7294309),\n",
       " 'San Joaquin': (10.5887998, 122.1396745),\n",
       " 'San Rafael': (11.1467423, 122.831015),\n",
       " 'Santa Barbara': (10.8166467, 122.5485873),\n",
       " 'Sara': (11.2932407, 123.000095),\n",
       " 'Tigbauan': (10.7283347, 122.3787597),\n",
       " 'Tubungan': (10.7893861, 122.2767313),\n",
       " 'Zarraga': (10.8283042, 122.6164409)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T15:20:52.917897456Z",
     "start_time": "2025-04-06T15:09:03.051024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the weather data for each municipality (running list, as we have limited calls per day)\n",
    "weather_data = utils.weather_to_jsonl(municipal_coords, 'municipal_weather_data.jsonl', rewrite_file=False)"
   ],
   "id": "7cb634644785a0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajuy already exists in the file. Skipping...\n",
      "Alimodian already exists in the file. Skipping...\n",
      "Anilao already exists in the file. Skipping...\n",
      "Badiangan already exists in the file. Skipping...\n",
      "Balasan already exists in the file. Skipping...\n",
      "Banate already exists in the file. Skipping...\n",
      "Barotac Nuevo already exists in the file. Skipping...\n",
      "Barotac Viejo already exists in the file. Skipping...\n",
      "Batad already exists in the file. Skipping...\n",
      "Bingawan already exists in the file. Skipping...\n",
      "Cabatuan already exists in the file. Skipping...\n",
      "Calinog already exists in the file. Skipping...\n",
      "Carles already exists in the file. Skipping...\n",
      "Passi City already exists in the file. Skipping...\n",
      "Concepcion already exists in the file. Skipping...\n",
      "Dingle already exists in the file. Skipping...\n",
      "Coordinates 11.07205581665039°N 122.58206939697266°E\n",
      "Elevation 36.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "Dumangas already exists in the file. Skipping...\n",
      "Estancia already exists in the file. Skipping...\n",
      "Guimbal already exists in the file. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miniloda/Documents/GitHub/Math-198.1---Special-Problem/utils.py:195: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hourly_data[\"date\"] = hourly_data[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
      "/home/miniloda/Documents/GitHub/Math-198.1---Special-Problem/utils.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hourly_data[\"municipality\"] = municipality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 10.720561981201172°N 122.59717559814453°E\n",
      "Elevation 8.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "Igbaras already exists in the file. Skipping...\n",
      "Janiuay already exists in the file. Skipping...\n",
      "Lambunao already exists in the file. Skipping...\n",
      "Leganes already exists in the file. Skipping...\n",
      "Lemery already exists in the file. Skipping...\n",
      "Leon already exists in the file. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miniloda/Documents/GitHub/Math-198.1---Special-Problem/utils.py:195: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hourly_data[\"date\"] = hourly_data[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
      "/home/miniloda/Documents/GitHub/Math-198.1---Special-Problem/utils.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hourly_data[\"municipality\"] = municipality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maasin already exists in the file. Skipping...\n",
      "Miagao already exists in the file. Skipping...\n",
      "Mina already exists in the file. Skipping...\n",
      "New Lucena already exists in the file. Skipping...\n",
      "Oton already exists in the file. Skipping...\n",
      "Pavia already exists in the file. Skipping...\n",
      "Pototan already exists in the file. Skipping...\n",
      "San Dionisio already exists in the file. Skipping...\n",
      "San Enrique already exists in the file. Skipping...\n",
      "San Joaquin already exists in the file. Skipping...\n",
      "San Rafael already exists in the file. Skipping...\n",
      "Santa Barbara already exists in the file. Skipping...\n",
      "Sara already exists in the file. Skipping...\n",
      "Tigbauan already exists in the file. Skipping...\n",
      "Tubungan already exists in the file. Skipping...\n",
      "Zarraga already exists in the file. Skipping...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T15:21:36.251335Z",
     "start_time": "2025-04-06T15:21:14.837042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import data_cleaning_utils\n",
    "\n",
    "# for loop the municipalities and save the data\n",
    "with open('municipals.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        municipal = line.strip()\n",
    "        data_cleaning_utils.get_merged_df(municipal)"
   ],
   "id": "2200896333043944",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data for Ajuy\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Ajuy has been cleaned and saved to data/Merged Data/Ajuy_merged.csv\n",
      "Cleaning data for Alimodian\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      1 2014-01-13\n",
      "2  2014     3      1 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Alimodian has been cleaned and saved to data/Merged Data/Alimodian_merged.csv\n",
      "Cleaning data for Anilao\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Anilao has been cleaned and saved to data/Merged Data/Anilao_merged.csv\n",
      "Cleaning data for Badiangan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Badiangan has been cleaned and saved to data/Merged Data/Badiangan_merged.csv\n",
      "Cleaning data for Balasan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Balasan has been cleaned and saved to data/Merged Data/Balasan_merged.csv\n",
      "Cleaning data for Banate\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      1 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Banate has been cleaned and saved to data/Merged Data/Banate_merged.csv\n",
      "Cleaning data for Barotac Nuevo\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Barotac Nuevo has been cleaned and saved to data/Merged Data/Barotac Nuevo_merged.csv\n",
      "Cleaning data for Barotac Viejo\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      1 2014-02-03\n",
      "Data for Barotac Viejo has been cleaned and saved to data/Merged Data/Barotac Viejo_merged.csv\n",
      "Cleaning data for Batad\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      1 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Batad has been cleaned and saved to data/Merged Data/Batad_merged.csv\n",
      "Cleaning data for Bingawan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      2 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Bingawan has been cleaned and saved to data/Merged Data/Bingawan_merged.csv\n",
      "Cleaning data for Cabatuan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-06\n",
      "1  2014     2      3 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Cabatuan has been cleaned and saved to data/Merged Data/Cabatuan_merged.csv\n",
      "Cleaning data for Calinog\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      1 2014-01-13\n",
      "2  2014     3      1 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      2 2014-02-03\n",
      "Data for Calinog has been cleaned and saved to data/Merged Data/Calinog_merged.csv\n",
      "Cleaning data for Carles\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Carles has been cleaned and saved to data/Merged Data/Carles_merged.csv\n",
      "Cleaning data for Passi City\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      2 2014-01-06\n",
      "1  2014     2      1 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Passi City has been cleaned and saved to data/Merged Data/Passi City_merged.csv\n",
      "Cleaning data for Concepcion\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Concepcion has been cleaned and saved to data/Merged Data/Concepcion_merged.csv\n",
      "Cleaning data for Dingle\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Dingle has been cleaned and saved to data/Merged Data/Dingle_merged.csv\n",
      "Cleaning data for Duenas\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      1 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Duenas has been cleaned and saved to data/Merged Data/Duenas_merged.csv\n",
      "Cleaning data for Dumangas\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      1 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Dumangas has been cleaned and saved to data/Merged Data/Dumangas_merged.csv\n",
      "Cleaning data for Estancia\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Estancia has been cleaned and saved to data/Merged Data/Estancia_merged.csv\n",
      "Cleaning data for Guimbal\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      2 2014-01-06\n",
      "1  2014     2      1 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Guimbal has been cleaned and saved to data/Merged Data/Guimbal_merged.csv\n",
      "Cleaning data for Iloilo City\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1     12 2014-01-06\n",
      "1  2014     2     13 2014-01-13\n",
      "2  2014     3      7 2014-01-20\n",
      "3  2014     4     12 2014-01-27\n",
      "4  2014     5      5 2014-02-03\n",
      "Data for Iloilo City has been cleaned and saved to data/Merged Data/Iloilo City_merged.csv\n",
      "Cleaning data for Igbaras\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Igbaras has been cleaned and saved to data/Merged Data/Igbaras_merged.csv\n",
      "Cleaning data for Janiuay\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      2 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      1 2014-02-03\n",
      "Data for Janiuay has been cleaned and saved to data/Merged Data/Janiuay_merged.csv\n",
      "Cleaning data for Lambunao\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      1 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Lambunao has been cleaned and saved to data/Merged Data/Lambunao_merged.csv\n",
      "Cleaning data for Leganes\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Leganes has been cleaned and saved to data/Merged Data/Leganes_merged.csv\n",
      "Cleaning data for Lemery\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Lemery has been cleaned and saved to data/Merged Data/Lemery_merged.csv\n",
      "Cleaning data for Leon\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      1 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Leon has been cleaned and saved to data/Merged Data/Leon_merged.csv\n",
      "Cleaning data for Maasin\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Maasin has been cleaned and saved to data/Merged Data/Maasin_merged.csv\n",
      "Cleaning data for Miagao\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      1 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Miagao has been cleaned and saved to data/Merged Data/Miagao_merged.csv\n",
      "Cleaning data for Mina\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Mina has been cleaned and saved to data/Merged Data/Mina_merged.csv\n",
      "Cleaning data for New Lucena\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      2 2014-01-13\n",
      "2  2014     3      1 2014-01-20\n",
      "3  2014     4      2 2014-01-27\n",
      "4  2014     5      1 2014-02-03\n",
      "Data for New Lucena has been cleaned and saved to data/Merged Data/New Lucena_merged.csv\n",
      "Cleaning data for Oton\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      2 2014-01-06\n",
      "1  2014     2      4 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Oton has been cleaned and saved to data/Merged Data/Oton_merged.csv\n",
      "Cleaning data for Pavia\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      2 2014-01-06\n",
      "1  2014     2      3 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      1 2014-01-27\n",
      "4  2014     5      1 2014-02-03\n",
      "Data for Pavia has been cleaned and saved to data/Merged Data/Pavia_merged.csv\n",
      "Cleaning data for Pototan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      1 2014-01-20\n",
      "3  2014     4      2 2014-01-27\n",
      "4  2014     5      3 2014-02-03\n",
      "Data for Pototan has been cleaned and saved to data/Merged Data/Pototan_merged.csv\n",
      "Cleaning data for San Dionisio\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for San Dionisio has been cleaned and saved to data/Merged Data/San Dionisio_merged.csv\n",
      "Cleaning data for San Enrique\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      1 2014-02-03\n",
      "Data for San Enrique has been cleaned and saved to data/Merged Data/San Enrique_merged.csv\n",
      "Cleaning data for San Joaquin\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for San Joaquin has been cleaned and saved to data/Merged Data/San Joaquin_merged.csv\n",
      "Cleaning data for San Rafael\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for San Rafael has been cleaned and saved to data/Merged Data/San Rafael_merged.csv\n",
      "Cleaning data for Santa Barbara\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-06\n",
      "1  2014     2      2 2014-01-13\n",
      "2  2014     3      1 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Santa Barbara has been cleaned and saved to data/Merged Data/Santa Barbara_merged.csv\n",
      "Cleaning data for Sara\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      2 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      1 2014-01-27\n",
      "4  2014     5      1 2014-02-03\n",
      "Data for Sara has been cleaned and saved to data/Merged Data/Sara_merged.csv\n",
      "Cleaning data for Tigbauan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      1 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      1 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Tigbauan has been cleaned and saved to data/Merged Data/Tigbauan_merged.csv\n",
      "Cleaning data for Tubungan\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      0 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Tubungan has been cleaned and saved to data/Merged Data/Tubungan_merged.csv\n",
      "Cleaning data for Zarraga\n",
      "   Year  Week  Cases  Year-Week\n",
      "0  2014     1      0 2014-01-06\n",
      "1  2014     2      1 2014-01-13\n",
      "2  2014     3      0 2014-01-20\n",
      "3  2014     4      0 2014-01-27\n",
      "4  2014     5      0 2014-02-03\n",
      "Data for Zarraga has been cleaned and saved to data/Merged Data/Zarraga_merged.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f1244d9f142b8b09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
